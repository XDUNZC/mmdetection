{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from mmdet.apis import init_detector, inference_detector, show_result\n",
    "from mmdet.models import build_detector\n",
    "import mmcv\n",
    "from mmcv.runner import load_checkpoint\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"  # specify which GPU(s) to be used\n",
    "device='cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count(),torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 23:55:40,864 - mmdet - INFO - load model from: open-mmlab://resnext101_64x4d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_file = 'configs/my.py'\n",
    "checkpoint_file = 'work_dirs/retinanet_x101_64x4d_fpn_1x/latest.pth'\n",
    "config = mmcv.Config.fromfile(config_file)\n",
    "model = build_detector(config.model)\n",
    "model = model.to(device)\n",
    "checkpoint = load_checkpoint(model, checkpoint_file)\n",
    "# build the model from a config file and a checkpoint file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = nn.Sequential(*list(model.children())[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetinaHead(\n",
       "  (loss_cls): FocalLoss()\n",
       "  (loss_bbox): SmoothL1Loss()\n",
       "  (relu): ReLU(inplace)\n",
       "  (cls_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "    (3): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (reg_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "    (3): ConvModule(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activate): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (retina_cls): Conv2d(256, 207, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (retina_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((1,3,1333,800))\n",
    "input = input.to(device)\n",
    "out = feature_extractor(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 167, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, num_features_in, num_anchors=9, num_classes=1, feature_extractor, feature_size=256):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.output = nn.Conv2d(feature_size, num_anchors * num_classes, kernel_size=3, padding=1)\n",
    "        self.output_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.act1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.act2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.act3(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        out = self.act4(out)\n",
    "\n",
    "        out = self.output(out)\n",
    "        out = self.output_act(out)\n",
    "\n",
    "        # out is B x C x W x H, with C = n_classes + n_anchors\n",
    "        out1 = out.permute(0, 2, 3, 1)\n",
    "\n",
    "        batch_size, width, height, channels = out1.shape\n",
    "\n",
    "        out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes)\n",
    "\n",
    "        return out2.contiguous().view(x.shape[0], -1, self.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(net.children())\n",
    "features = nn.Sequential(*layers[:-1]) \n",
    "classifier = nn.Sequential(layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (2): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (3): Linear(in_features=120, out_features=84, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_Net(nn.Module):\n",
    "\n",
    "    def __init__(self,features):\n",
    "        super(New_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.feature = features\n",
    "        \n",
    "        self.my_fc = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.feature(x)\n",
    "        x = self.my_fc(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0630, -0.0706, -0.0173,  ...,  0.0549, -0.0273, -0.0299],\n",
       "        [-0.0325,  0.0157, -0.0259,  ..., -0.0234, -0.0481, -0.0683],\n",
       "        [-0.0192, -0.0048, -0.0838,  ..., -0.0070, -0.0513,  0.0746],\n",
       "        ...,\n",
       "        [ 0.0795,  0.0245,  0.0496,  ...,  0.0551,  0.0851,  0.0637],\n",
       "        [ 0.0479,  0.0216, -0.0295,  ...,  0.0502, -0.0075,  0.0455],\n",
       "        [ 0.0087, -0.0057,  0.0590,  ..., -0.0453,  0.0217,  0.0326]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_dict['fc2.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = nn.functional.adaptive_max_pool2d(out[0],output_size = (7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4234,  0.4577,  0.4197,  ...,  0.4082,  0.7679,  0.4867],\n",
       "          [ 0.4059,  0.2055,  0.1826,  ...,  0.3216,  0.4519,  0.4478],\n",
       "          [ 0.3470,  0.3545,  0.4531,  ...,  0.2754,  0.2332,  0.3889],\n",
       "          ...,\n",
       "          [ 0.2054,  0.1445,  0.3225,  ...,  0.3655,  0.3462,  0.4838],\n",
       "          [ 0.2786,  0.2771,  0.3914,  ...,  0.2826,  0.5273,  0.4812],\n",
       "          [ 0.2303,  0.4568,  0.5721,  ...,  0.3019,  0.7221,  0.6295]],\n",
       "\n",
       "         [[ 0.3416,  0.2946,  0.1412,  ...,  0.3514,  0.4528,  0.2325],\n",
       "          [ 0.2826,  0.3564,  0.3662,  ...,  0.2742,  0.2651,  0.2651],\n",
       "          [ 0.4976,  0.2909,  0.2746,  ...,  0.1683,  0.3997,  0.3997],\n",
       "          ...,\n",
       "          [ 0.3665,  0.2900,  0.3425,  ...,  0.3427,  0.2635,  0.2479],\n",
       "          [ 0.3665,  0.2938,  0.2157,  ...,  0.2321,  0.2084,  0.3541],\n",
       "          [ 0.1769,  0.3102,  0.3385,  ...,  0.2321,  0.2487,  0.2691]],\n",
       "\n",
       "         [[ 0.3277,  0.6204,  0.3811,  ...,  0.2468,  0.2848,  0.2690],\n",
       "          [ 0.2822,  0.6204,  0.3696,  ...,  0.3363,  0.2983,  0.3482],\n",
       "          [ 0.3231,  0.4845,  0.5921,  ...,  0.3340,  0.4080,  0.2627],\n",
       "          ...,\n",
       "          [ 0.4772,  0.4169,  0.4553,  ...,  0.4594,  0.3774,  0.3753],\n",
       "          [ 0.4667,  0.3756,  0.4553,  ...,  0.3402,  0.4043,  0.3603],\n",
       "          [ 0.3275,  0.4946,  0.5472,  ...,  0.4102,  0.3939,  0.4319]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.5076,  0.5223,  0.6663,  ...,  0.4784,  0.5780,  0.4708],\n",
       "          [ 0.5067,  0.5396,  0.5090,  ...,  0.4159,  0.4278,  0.4199],\n",
       "          [ 0.6251,  0.5392,  0.5963,  ...,  0.5275,  0.5581,  0.4539],\n",
       "          ...,\n",
       "          [ 0.4752,  0.4847,  0.5133,  ...,  0.6186,  0.5456,  0.4231],\n",
       "          [ 0.5715,  0.5780,  0.6178,  ...,  0.4882,  0.4470,  0.4912],\n",
       "          [ 0.6091,  0.6527,  0.7454,  ...,  0.4946,  0.4898,  0.5885]],\n",
       "\n",
       "         [[ 0.0836,  0.0212,  0.1132,  ...,  0.0364,  0.1542,  0.1847],\n",
       "          [ 0.1215,  0.0023,  0.0551,  ...,  0.1646,  0.1211,  0.0120],\n",
       "          [ 0.1021,  0.2475, -0.0023,  ..., -0.0030,  0.0121,  0.0730],\n",
       "          ...,\n",
       "          [ 0.1390,  0.1206,  0.2275,  ...,  0.2554,  0.1112,  0.0404],\n",
       "          [ 0.1589, -0.0102,  0.1041,  ...,  0.1560,  0.3033,  0.0137],\n",
       "          [ 0.0833,  0.1052, -0.1181,  ...,  0.0679,  0.0132,  0.0408]],\n",
       "\n",
       "         [[ 0.3459,  0.2682,  0.2875,  ...,  0.0217,  0.1144,  0.3273],\n",
       "          [ 0.1859,  0.3305,  0.2032,  ...,  0.2216,  0.2216,  0.3513],\n",
       "          [ 0.2991,  0.1593,  0.1256,  ...,  0.2506,  0.3461,  0.2718],\n",
       "          ...,\n",
       "          [ 0.3145,  0.2261,  0.1677,  ...,  0.1912,  0.2186,  0.2019],\n",
       "          [ 0.3379,  0.3943,  0.3294,  ...,  0.1951,  0.3400,  0.3932],\n",
       "          [ 0.3368,  0.2935,  0.2612,  ...,  0.2359,  0.2189,  0.2370]]]],\n",
       "       device='cuda:2', grad_fn=<AdaptiveMaxPool2DBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x.append('123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append('456')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123', '456']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
